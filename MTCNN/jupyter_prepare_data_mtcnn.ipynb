{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for MTCNN\n",
    "\n",
    "This notebook is here to prepare the data for the MTCNN training. The MTCNN model is composed of 3 subnetworks. Pnet accepts images of size 12x12, Rnet 28x28 and Onet 48x48. The following framework goes through all the images of the given set, crop the faces and resize them to the crop size parameter. For each positive sample, it also crop a random negative sample. the \"nb_max_copy\" is a parameters that if > 1 allows to have more than 1 time the same face cropped (but slightly moved to the rigth, the left, up or down depending on the allowed space and the groundtruth). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framework(folder_img, folder_gt, resize, folder_store, threshold = 0.1, nb_max_copy = 5, crop_size = 20) :\n",
    "    \n",
    "    print(\"Loading images from folder : \", folder_img)\n",
    "    #folder=\"dcm_dataset.git/images/images\"\n",
    "    images, path_images = load_images_from_folder(folder_img)\n",
    "    print(\"Check dataset length : \", len(images))\n",
    "\n",
    "    # Load groundtruth :\n",
    "    print(\"Loading groundtruth from folder : \", folder_gt)\n",
    "    #folder=\"dcm_dataset.git\\groundtruth\"\n",
    "    groundtruth, path_groundtruth = load_all_groundtruth(folder_gt, 5)\n",
    "    print(\"Check groundtruth length : \", len(groundtruth))\n",
    "\n",
    "    # Change size :\n",
    "    #print(\"resizing to width = \", resize)\n",
    "    #resize_img_and_gt(resize, images, groundtruth)\n",
    "    \n",
    "    # Extract faces\n",
    "    print(\"Extracting faces, storing in : \", folder_store)\n",
    "    get_set_faces(images, groundtruth, folder_store, threshold, nb_max_copy, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from folder :  ../dataset/train_test/style2/img_train\n",
      "Check dataset length :  51\n",
      "Loading groundtruth from folder :  ../dataset/train_test/style2/gt_train\n",
      "Check groundtruth length :  51\n",
      "Extracting faces, storing in :  ../dataset/faces/style2/v0\n"
     ]
    }
   ],
   "source": [
    "folder_img=\"../dataset/train_test/style2/img_train\"\n",
    "folder_gt=\"../dataset/train_test/style2/gt_train\"\n",
    "folder_store=\"../dataset/faces/style2/v0\"\n",
    "\n",
    "framework(folder_img, folder_gt, 1200, folder_store, threshold = 0.2, nb_max_copy = 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
